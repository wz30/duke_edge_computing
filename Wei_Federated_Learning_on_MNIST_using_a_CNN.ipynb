{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Wei Federated Learning on MNIST using a CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "t1tIa0_Sb7R7"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wz30/duke_edge_computing/blob/main/Wei_Federated_Learning_on_MNIST_using_a_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchYwwy0b7R5"
      },
      "source": [
        "\n",
        "\n",
        "## Federated Learning on MNIST using a CNN with PyTorch & PySyft\n",
        "\n",
        "\n",
        "### Context \n",
        "\n",
        "Federated learning is a machine learning technique that trains an algorithm across multiple decentralized edge devices or servers holding local data samples, without exchanging their data samples. \n",
        "\n",
        "\n",
        "We use Google Colaboratory to execute code\n",
        "###related reference: \n",
        "PyTorch(https://github.com/pytorch/examples/blob/master/mnist/main.py)\n",
        "\n",
        "PySyft (https://github.com/OpenMined/PySyft/)\n",
        "\n",
        "Colaboratory (https://colab.research.google.com/) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTuzyULuk3mW"
      },
      "source": [
        "Colaboratory support for importing a library that's not in Colaboratory by default. In this tutorial,we just need install syft package by pip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJrwdAEQiquA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36ff84e0-51b2-4f64-adde-8cda9217083f"
      },
      "source": [
        "! pip install syft==0.2.9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft==0.2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/73/891ba1dca7e0ba77be211c36688f083184d8c9d5901b8cd59cbf867052f3/syft-0.2.9-py3-none-any.whl (433kB)\n",
            "\r\u001b[K     |▊                               | 10kB 12.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30kB 8.8MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 276kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 286kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 327kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 348kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 368kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 389kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 399kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 430kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 440kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.0.2)\n",
            "Collecting numpy~=1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 47.5MB/s \n",
            "\u001b[?25hCollecting tornado==4.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/7b/e29ab3d51c8df66922fea216e2bddfcb6430fb29620e5165b16a216e0d3c/tornado-4.5.3.tar.gz (484kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.1.2)\n",
            "Collecting psutil==5.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 35.7MB/s \n",
            "\u001b[?25hCollecting shaloop==0.2.1-alpha.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/8e/6c4493280d55199161c2eea896327c740195cf16cc74c5393c08eababc83/shaloop-0.2.1_alpha.11-py3-none-manylinux1_x86_64.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 49.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.1)\n",
            "Collecting importlib-resources~=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/2d/88f166bcaadc09d9fdbf1c336ad118e01b7fe1155e15675e125be2ff1899/importlib_resources-1.5.0-py2.py3-none-any.whl\n",
            "Collecting websockets~=8.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.5MB/s \n",
            "\u001b[?25hCollecting lz4~=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/dacc3cbb33a9ded9e2e57f48707e8842f1080997901578ebddaa0e031646/lz4-3.0.2-cp37-cp37m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 43.7MB/s \n",
            "\u001b[?25hCollecting aiortc==0.9.28\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c5/0c15e562c5ea1531e8c7db1bcd524e53619cc27a228f3f28d2ba55544d38/aiortc-0.9.28-cp37-cp37m-manylinux2010_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 35.5MB/s \n",
            "\u001b[?25hCollecting openmined.threepio==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/38/df6367693c7f3808f076cd8c2647c434a04adda2bbb2435dadefe7258fd4/openmined.threepio-0.2.0.tar.gz (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[?25hCollecting Pillow>=7.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6d/b719ae8e21660a6a962636896dc4b7d657ef451a3ab941516401846ac5cb/Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 34.9MB/s \n",
            "\u001b[?25hCollecting RestrictedPython~=5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/cc/28c4d966615a46b03be4dac0f2c6e713412efbf2f85428eeb9618c4f6f0c/RestrictedPython-5.1-py2.py3-none-any.whl\n",
            "Collecting tblib~=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/de/dca3e651ca62e59c08d324f4a51467fa4b8cbeaafb883b5e83720b4d4a47/tblib-1.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dill~=0.3.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.3.3)\n",
            "Collecting notebook==5.7.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/36/89ebfffc9dd8c8dbd81c1ffb53e3d4233ee666414c143959477cb07cc5f5/notebook-5.7.8-py2.py3-none-any.whl (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0MB 49.4MB/s \n",
            "\u001b[?25hCollecting torch~=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
            "\u001b[?25hCollecting flask-socketio~=4.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Collecting requests~=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n",
            "\u001b[?25hCollecting torchvision~=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 30.1MB/s \n",
            "\u001b[?25hCollecting phe~=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/32/0e/568e97b014eb14e794a1258a341361e9da351dc6240c63b89e1541e3341c/phe-1.4.0.tar.gz\n",
            "Collecting websocket-client~=0.57.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 31.1MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt==0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hCollecting syft-proto~=0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/88/67edf7836ac4eab723416933cd663c4f87753d3ff31337f91701c0b75474/syft_proto-0.5.3-py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (7.1.2)\n",
            "Requirement already satisfied: cffi>=1 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (1.14.5)\n",
            "Requirement already satisfied: pycparser>=2 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (2.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.4.1)\n",
            "Collecting aioice<0.7.0,>=0.6.17\n",
            "  Downloading https://files.pythonhosted.org/packages/8b/86/e3cdf660b67da7a9a7013253db5db7cf786a52296cb40078db1206177698/aioice-0.6.18-py3-none-any.whl\n",
            "Collecting av<9.0.0,>=8.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 84kB/s \n",
            "\u001b[?25hCollecting pyee>=6.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/0a/933b3931107e1da186963fd9bb9bceb9a613cff034cb0fb3b0c61003f357/pyee-8.1.0-py2.py3-none-any.whl\n",
            "Collecting crc32c\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/85/4656cc0ac33be2725d6de41eabfeb72f86c194fe26decf28162d72f9a642/crc32c-2.2-cp37-cp37m-manylinux2010_x86_64.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.7MB/s \n",
            "\u001b[?25hCollecting pylibsrtp>=0.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/24/9c2060d5f2d831091c7bb41428d17fd20e839959f1e78e6930329b21c0a7/pylibsrtp-0.6.8-cp37-cp37m-manylinux2010_x86_64.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.10.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.9.2)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.0.5)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.3.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (22.0.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.6.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.9.0)\n",
            "Collecting python-socketio>=4.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/15/70ce203227a6c21931e0a1a04552887e8f08f7556459d65e901674f026fc/python_socketio-5.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2020.12.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.5.0->syft==0.2.9) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.5.2->syft==0.2.9) (3.12.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft==0.2.9) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->importlib-resources~=1.5.0->syft==0.2.9) (3.7.4.3)\n",
            "Collecting netifaces\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/18/fd6e9c71a35b67a73160ec80a49da63d1eed2d2055054cc2995714949132/netifaces-0.10.9.tar.gz\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook==5.7.8->syft==0.2.9) (5.5.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.7.8->syft==0.2.9) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.7.8->syft==0.2.9) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (2.8.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (3.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.4.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (2.6.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (1.4.3)\n",
            "Collecting bidict>=0.21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/d4/eaf9242722bf991e0955380dd6168020cb15a71cc0d3cc2373f4911b1f1d/bidict-0.21.2-py2.py3-none-any.whl\n",
            "Collecting python-engineio>=4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ff/8c5392bcc6beb31aaeb759fce5de2141ae79a86018ad0173008f76b26085/python_engineio-4.0.1-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->syft-proto~=0.5.2->syft==0.2.9) (54.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (2.4.7)\n",
            "Building wheels for collected packages: tornado, psutil, openmined.threepio, phe, netifaces\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434002 sha256=ee2b416a1a713e3fad5b16a2684c4c0a73e44b4288f199a6dd1e63d1fe428432\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/bf/f4/b68fa69596986881b397b18ff2b9af5f8181233aadcc9f76fd\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276444 sha256=2f87a27673213965b2e96f2d59596ab0e8b051100914d876d92197d7971f49c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57\n",
            "  Building wheel for openmined.threepio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openmined.threepio: filename=openmined.threepio-0.2.0-cp37-none-any.whl size=80095 sha256=8cae09c481bb538abb5e8ea3f2b83a03e43654d187f77881846db1eaf89ffc1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/a5/c5/7e67449f5d4d487e1d3a583ba51d27403b315b18ef2e48a13c\n",
            "  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=98f75ceb53f7317f0d968393dba337567588bcfbaa25591a8e75125d90665c00\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/dc/36/dcb6bf0f1b9907e7b710ace63e64d08e7022340909315fdea4\n",
            "  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netifaces: filename=netifaces-0.10.9-cp37-cp37m-linux_x86_64.whl size=37421 sha256=3d9b642b2d6d6baa0db130c89ac4d489ba0853fa4f26029423abcfc2c5fa8568\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/8f/f3/7054578f04c904f70757c5c85a6e2823baa69d42365526e93d\n",
            "Successfully built tornado psutil openmined.threepio phe netifaces\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version >= \"3.0\", but you'll have notebook 5.7.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.1.1 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tornado, psutil, shaloop, importlib-resources, websockets, lz4, netifaces, aioice, av, pyee, crc32c, cryptography, pylibsrtp, aiortc, openmined.threepio, Pillow, RestrictedPython, tblib, notebook, torch, bidict, python-engineio, python-socketio, flask-socketio, idna, requests, torchvision, phe, websocket-client, requests-toolbelt, syft-proto, syft\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Found existing installation: importlib-resources 5.1.2\n",
            "    Uninstalling importlib-resources-5.1.2:\n",
            "      Successfully uninstalled importlib-resources-5.1.2\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: tblib 1.7.0\n",
            "    Uninstalling tblib-1.7.0:\n",
            "      Successfully uninstalled tblib-1.7.0\n",
            "  Found existing installation: notebook 5.3.1\n",
            "    Uninstalling notebook-5.3.1:\n",
            "      Successfully uninstalled notebook-5.3.1\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed Pillow-8.1.2 RestrictedPython-5.1 aioice-0.6.18 aiortc-0.9.28 av-8.0.3 bidict-0.21.2 crc32c-2.2 cryptography-3.4.6 flask-socketio-4.2.1 idna-2.8 importlib-resources-1.5.0 lz4-3.0.2 netifaces-0.10.9 notebook-5.7.8 numpy-1.18.5 openmined.threepio-0.2.0 phe-1.4.0 psutil-5.7.0 pyee-8.1.0 pylibsrtp-0.6.8 python-engineio-4.0.1 python-socketio-5.1.0 requests-2.22.0 requests-toolbelt-0.9.1 shaloop-0.2.1a11 syft-0.2.9 syft-proto-0.5.3 tblib-1.6.0 torch-1.4.0 torchvision-0.5.0 tornado-4.5.3 websocket-client-0.57.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy",
                  "psutil",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhodKoN5TPdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d37256-3d6f-4406-be90-b6e34c3a3e9b"
      },
      "source": [
        "# !pip install torch==1.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1tIa0_Sb7R7"
      },
      "source": [
        "### Imports and model specifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEviEX-gb7R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53fa096-f654-4243-e271-09066380959d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import sys\n",
        "#torch version should be 1.4.0 to be compatiable with syft\n",
        "print(torch.__version__)\n",
        "print(sys.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n",
            "3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg9SUSkmb7R_"
      },
      "source": [
        "And than those specific to PySyft. In particular we define remote workers `alice` and `bob`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_vhLSp2b7SA"
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIHnmPZsb7SD"
      },
      "source": [
        "We define the setting of the learning task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcKN9QwKb7SD"
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 2\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8N_9HlOb7SG"
      },
      "source": [
        "### Data loading and sending to workers\n",
        "We first load the data and transform the training Dataset into a Federated Dataset split across the workers using the `.federate` method. This federated dataset is now given to a Federated DataLoader. The test dataset remains unchanged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzPkFor0ytLi"
      },
      "source": [
        "mnist_train = datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gthDE-jGb7SG"
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx91IbmdJsPP",
        "outputId": "8f16c7dc-1285-4e4b-c07d-59e88b235ad2"
      },
      "source": [
        "print(len((test_loader.dataset)[0][0][0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4jxjJNj3899",
        "outputId": "4d258252-d06d-418d-b725-20105eed3962"
      },
      "source": [
        "\n",
        "t1 = torch.tensor([[1, 1, 1],\n",
        "        [2, 2, 2],\n",
        "        [3, 3, 3]])\n",
        "t2 = torch.tensor([[1, 1, 1],\n",
        "        [2, 2, 2],\n",
        "        [3, 3, 3]])\n",
        "t1.size()\n",
        "t3 = torch.cat(\n",
        "    (t1,t2)\n",
        "    ,dim=0\n",
        ")\n",
        "t4 = torch.cat(\n",
        "    (t3,t2)\n",
        "    ,dim=0\n",
        ")\n",
        "t4 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [2, 2, 2],\n",
              "        [3, 3, 3],\n",
              "        [1, 1, 1],\n",
              "        [2, 2, 2],\n",
              "        [3, 3, 3],\n",
              "        [1, 1, 1],\n",
              "        [2, 2, 2],\n",
              "        [3, 3, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DES9c_9Gi1Kz",
        "outputId": "b1506963-875c-41d4-d626-0e24bb71b232"
      },
      "source": [
        "from tree import tree_benchmark\n",
        "print(tree_benchmark.TIME_UNITS)\n",
        "print(type(\"str\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 's'), (0.001, 'ms'), (1e-06, 'us'), (1e-09, 'ns')]\n",
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnGATq50H1pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5867daaf-6600-4f23-c1bf-829e8d04424b"
      },
      "source": [
        "tup = [(1,2),(2,3),(4,1),(1,2),(2,3),(4,1),(1,2),(2,3),(4,1),(7,5)]\n",
        "\n",
        "[x for (x,y) in tup][int(len(tup)*0.3):]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 4, 1, 2, 4, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQZiY8SyKz50"
      },
      "source": [
        "torch.utils.data.DataLoader?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBak-EmJb7SK"
      },
      "source": [
        "### CNN specification\n",
        "Here we use exactly the same CNN as in the official example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCnqrCctb7SK"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTl33ce2b7SM"
      },
      "source": [
        "### Define the train and test functions\n",
        "For the train function, because the data batches are distributed across `alice` and `bob`, you need to send the model to the right location for each batch. Then, you perform all the operations remotely with the same syntax like you're doing local PyTorch. When you're done, you get back the model updated and the loss to look for improvement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spdx7zqwb7SN"
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0itDBbWb7SO"
      },
      "source": [
        "The test function does not change!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-thFXq5-b7SP"
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLevv-Zmb7SR"
      },
      "source": [
        "### Launch the training !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf8Q9Yc5b7SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dccefc-23be-40a7-dd80-e6b2b901ddd6"
      },
      "source": [
        "%%time\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.303102\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.210071\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.968947\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 1.459771\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.979385\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.749077\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.573528\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.583597\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.422385\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.480115\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.375935\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.345905\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.416229\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.342528\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.285184\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.230878\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.205240\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.415740\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.305404\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.147625\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.350299\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.279713\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.139383\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.130617\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.115925\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.235055\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.336935\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.191750\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.162299\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.166082\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.130912\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.224724\n",
            "\n",
            "Test set: Average loss: 0.1526, Accuracy: 9546/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.086058\n",
            "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.088845\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.256614\n",
            "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.330241\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.176724\n",
            "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.417692\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.062695\n",
            "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.188451\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.308580\n",
            "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.135945\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.111206\n",
            "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.077115\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.140094\n",
            "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.115682\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.094725\n",
            "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.078241\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.109225\n",
            "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.079610\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.160878\n",
            "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.083428\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.071683\n",
            "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.119550\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.119312\n",
            "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.153353\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.189729\n",
            "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.056636\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.081814\n",
            "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.102896\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.072645\n",
            "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.128968\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.140760\n",
            "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.094093\n",
            "\n",
            "Test set: Average loss: 0.0985, Accuracy: 9703/10000 (97%)\n",
            "\n",
            "CPU times: user 4min 40s, sys: 17.9 s, total: 4min 58s\n",
            "Wall time: 4min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}